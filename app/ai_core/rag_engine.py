"""
RAG ì—”ì§„
- ë²¡í„° ê²€ìƒ‰ (FAISS)
- ë¬¸ì„œ ê²€ìƒ‰ ë¡œì§
- Upstage Embeddings í†µí•©
"""

from typing import List, Optional
from sqlalchemy.orm import Session
import numpy as np
import os
from pathlib import Path
import json
import pickle
import logging

from app.core.config import settings
from app.models import models
from app.ai_core.llm_client import llm_client
from app.ai_core.prompts import WELFARE_SUMMARY_PROMPT

logger = logging.getLogger(__name__)

# FAISS ì„í¬íŠ¸
try:
    import faiss
    FAISS_AVAILABLE = True
except ImportError:
    FAISS_AVAILABLE = False
    print("ê²½ê³ : FAISSê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install faiss-cpuë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")


class VectorStore:
    """FAISS ê¸°ë°˜ ë²¡í„° ì €ì¥ì†Œ"""
    
    def __init__(self, dimension: Optional[int] = None, index_path: Optional[str] = None):
        """
        dimension: ì„ë² ë”© ì°¨ì› (Noneì´ë©´ ì„¤ì •ì—ì„œ ìë™ ê°ì§€)
        index_path: FAISS ì¸ë±ìŠ¤ íŒŒì¼ ê²½ë¡œ
        """
        # ì°¨ì› ìë™ ê°ì§€ (ì„¤ì •ì—ì„œ ê°€ì ¸ì˜¤ê¸°)
        if dimension is None:
            dimension = settings.EMBEDDING_DIMENSION
        self.dimension = dimension
        self.index_path = index_path or os.path.join(settings.VECTOR_DB_PATH, "faiss.index")
        self.id_to_welfare_id_path = os.path.join(settings.VECTOR_DB_PATH, "id_mapping.pkl")
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(os.path.dirname(self.index_path), exist_ok=True)
        
        # FAISS ì¸ë±ìŠ¤ ì´ˆê¸°í™”
        if FAISS_AVAILABLE:
            if os.path.exists(self.index_path):
                self.index = faiss.read_index(self.index_path)
                # ID ë§¤í•‘ ë¡œë“œ
                if os.path.exists(self.id_to_welfare_id_path):
                    with open(self.id_to_welfare_id_path, 'rb') as f:
                        self.id_to_welfare_id = pickle.load(f)
                else:
                    self.id_to_welfare_id = {}
            else:
                # L2 ê±°ë¦¬ ê¸°ë°˜ ì¸ë±ìŠ¤ ìƒì„±
                self.index = faiss.IndexFlatL2(dimension)
                self.id_to_welfare_id = {}
        else:
            self.index = None
            self.id_to_welfare_id = {}
    
    def add_vectors(self, vectors: np.ndarray, welfare_ids: List[int]):
        """ë²¡í„°ì™€ welfare IDë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤."""
        if not FAISS_AVAILABLE or self.index is None:
            return
        
        if len(vectors) == 0:
            return
        
        # numpy ë°°ì—´ë¡œ ë³€í™˜
        if not isinstance(vectors, np.ndarray):
            vectors = np.array(vectors).astype('float32')
        
        # ì°¨ì› í™•ì¸
        if vectors.shape[1] != self.dimension:
            raise ValueError(f"ë²¡í„° ì°¨ì›ì´ ë§ì§€ ì•ŠìŠµë‹ˆë‹¤. ì˜ˆìƒ: {self.dimension}, ì‹¤ì œ: {vectors.shape[1]}")
        
        # í˜„ì¬ ì¸ë±ìŠ¤ í¬ê¸°
        start_id = self.index.ntotal
        
        # ì¸ë±ìŠ¤ì— ì¶”ê°€
        self.index.add(vectors)
        
        # ID ë§¤í•‘ ì €ì¥
        for i, welfare_id in enumerate(welfare_ids):
            self.id_to_welfare_id[start_id + i] = welfare_id
    
    def search(self, query_vector: np.ndarray, k: int = 10) -> List[int]:
        """
        ìœ ì‚¬ë„ ê²€ìƒ‰
        - query_vector: ì¿¼ë¦¬ ë²¡í„° (1ì°¨ì› ë°°ì—´)
        - k: ë°˜í™˜í•  ê²°ê³¼ ìˆ˜
        - ë°˜í™˜: welfare ID ë¦¬ìŠ¤íŠ¸
        """
        if not FAISS_AVAILABLE or self.index is None or self.index.ntotal == 0:
            return []
        
        # numpy ë°°ì—´ë¡œ ë³€í™˜
        if not isinstance(query_vector, np.ndarray):
            query_vector = np.array([query_vector]).astype('float32')
        else:
            query_vector = query_vector.reshape(1, -1).astype('float32')
        
        # ê²€ìƒ‰
        distances, indices = self.index.search(query_vector, min(k, self.index.ntotal))
        
        # welfare IDë¡œ ë³€í™˜
        welfare_ids = []
        for idx in indices[0]:
            if idx in self.id_to_welfare_id:
                welfare_ids.append(self.id_to_welfare_id[idx])
        
        return welfare_ids
    
    def save(self):
        """ì¸ë±ìŠ¤ë¥¼ íŒŒì¼ì— ì €ì¥í•©ë‹ˆë‹¤."""
        if not FAISS_AVAILABLE or self.index is None:
            return
        
        faiss.write_index(self.index, self.index_path)
        
        # ID ë§¤í•‘ ì €ì¥
        with open(self.id_to_welfare_id_path, 'wb') as f:
            pickle.dump(self.id_to_welfare_id, f)
    
    def get_size(self) -> int:
        """ì €ì¥ëœ ë²¡í„° ìˆ˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        if self.index is None:
            return 0
        return self.index.ntotal


# ì „ì—­ ë²¡í„° ì €ì¥ì†Œ ì¸ìŠ¤í„´ìŠ¤
_vector_store: Optional[VectorStore] = None


def get_vector_store() -> VectorStore:
    """ë²¡í„° ì €ì¥ì†Œ ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    global _vector_store
    if _vector_store is None:
        _vector_store = VectorStore()
    return _vector_store


def get_embedding(text: str, is_query: bool = False, provider: Optional[str] = None) -> List[float]:
    """
    í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ì„ë² ë”©
    - Upstage ë˜ëŠ” Gemini Embeddings API ì‚¬ìš©
    - í…ìŠ¤íŠ¸ ì •ì œ í›„ ì„ë² ë”© ìƒì„±
    
    Args:
        text: ì„ë² ë”©í•  í…ìŠ¤íŠ¸
        is_query: Trueì´ë©´ ì¿¼ë¦¬ ëª¨ë¸ ì‚¬ìš© (ê²€ìƒ‰ìš©), Falseì´ë©´ ë¬¸ì„œ ëª¨ë¸ ì‚¬ìš© (ì €ì¥ìš©)
        provider: "upstage" ë˜ëŠ” "gemini" (Noneì´ë©´ ì„¤ì •ê°’ ì‚¬ìš©)
    """
    if not text or not text.strip():
        # ê¸°ë³¸ ì°¨ì›
        return [0.0] * settings.EMBEDDING_DIMENSION
    
    # llm_clientì˜ get_text_embedding ë©”ì„œë“œ ì‚¬ìš©
    try:
        return llm_client.get_text_embedding(text, is_query=is_query, provider=provider)
    except Exception as e:
        logger.error(f"ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
        raise ValueError(
            f"ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}. "
            ".env íŒŒì¼ì— UPSTAGE_API_KEYë¥¼ í™•ì¸í•˜ì„¸ìš”."
        )


def similarity_search(
    query_embedding: List[float],
    limit: int = 10
) -> List[int]:
    """
    ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰
    - query_embedding: ì¿¼ë¦¬ ë²¡í„°
    - limit: ë°˜í™˜í•  ê²°ê³¼ ìˆ˜
    - ë°˜í™˜: welfare ID ë¦¬ìŠ¤íŠ¸
    """
    vector_store = get_vector_store()
    return vector_store.search(np.array(query_embedding), k=limit)


def search_welfare_rag(
    db: Session,
    query: str,
    region: Optional[str] = None,
    age: Optional[int] = None,
    limit: int = 10
) -> List[models.Welfare]:
    """
    RAG ê¸°ë°˜ ë³µì§€ ì •ë³´ ê²€ìƒ‰
    - ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰
    - ì‚¬ìš©ì í”„ë¡œí•„ ê¸°ë°˜ í•„í„°ë§
    - LLM ìš”ì•½ ìƒì„±
    """
    # ì¿¼ë¦¬ í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ì„ë² ë”© (ì¿¼ë¦¬ ëª¨ë¸ ì‚¬ìš©)
    query_embedding = get_embedding(query, is_query=True)
    
    # ë²¡í„° DBì—ì„œ ìœ ì‚¬ë„ ê²€ìƒ‰
    welfare_ids = similarity_search(query_embedding, limit=limit * 2)  # í•„í„°ë§ì„ ìœ„í•´ ë” ë§ì´ ê°€ì ¸ì˜´
    
    # DBì—ì„œ ë³µì§€ ì •ë³´ ì¡°íšŒ
    if welfare_ids:
        welfares = db.query(models.Welfare).filter(
            models.Welfare.id.in_(welfare_ids)
        ).all()
        
        # ID ìˆœì„œëŒ€ë¡œ ì •ë ¬ (ê²€ìƒ‰ ì ìˆ˜ ìˆœì„œ ìœ ì§€)
        welfare_dict = {w.id: w for w in welfares}
        welfares = [welfare_dict[id] for id in welfare_ids if id in welfare_dict]
    else:
        # ë²¡í„° ê²€ìƒ‰ ì‹¤íŒ¨ ì‹œ í‚¤ì›Œë“œ ê²€ìƒ‰ìœ¼ë¡œ ëŒ€ì²´
        from app.models.crud import search_welfares
        welfares = search_welfares(
            db=db,
            keyword=query,
            region=region,
            age=age,
            limit=limit
        )
    
    # ì§€ì—­/ë‚˜ì´ í•„í„°ë§
    if region:
        welfares = [w for w in welfares if region in (w.region or "")]
    if age:
        welfares = [
            w for w in welfares
            if (w.age_min is None or w.age_min <= age) and
               (w.age_max is None or w.age_max >= age)
        ]
    
    # ìƒìœ„ limitê°œë§Œ ë°˜í™˜
    welfares = welfares[:limit]
    
    # LLMì„ ì‚¬ìš©í•˜ì—¬ 17ì„¸ ìˆ˜ì¤€ìœ¼ë¡œ ìš”ì•½ ìƒì„±
    for welfare in welfares:
        if not welfare.summary and welfare.full_text:
            try:
                welfare.summary = summarize_welfare(welfare.full_text)
            except Exception as e:
                print(f"ìš”ì•½ ìƒì„± ì˜¤ë¥˜ (ID: {welfare.id}): {e}")
                # ìš”ì•½ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ìš”ì•½ ì‚¬ìš©
                welfare.summary = welfare.full_text[:200] + "..." if len(welfare.full_text) > 200 else welfare.full_text
    
    return welfares


def summarize_welfare(text: str, target_level: str = "17ì„¸") -> str:
    """
    ë³µì§€ ì •ë³´ë¥¼ 17ì„¸ ìˆ˜ì¤€ìœ¼ë¡œ ìš”ì•½
    - LLM API í†µí•©
    """
    prompt = WELFARE_SUMMARY_PROMPT.format(
        target_level=target_level,
        text=text
    )
    
    # LLM API í˜¸ì¶œ
    summary = llm_client.summarize_text(text, target_level)
    
    return summary


def store_welfare_embedding(db: Session, welfare: models.Welfare):
    """
    ë³µì§€ ì •ë³´ì˜ ì„ë² ë”©ì„ ìƒì„±í•˜ì—¬ ì €ì¥
    - DBì— ì„ë² ë”© ì €ì¥
    - ë²¡í„° DBì—ë„ ì €ì¥
    """
    if not welfare.full_text:
        return
    
    # ì„ë² ë”© ìƒì„±
    embedding = get_embedding(welfare.full_text)
    
    # DBì— ì €ì¥
    welfare.embedding = embedding
    db.commit()
    
    # ë²¡í„° DBì— ì¶”ê°€
    vector_store = get_vector_store()
    vector_store.add_vectors(
        np.array([embedding]).astype('float32'),
        [welfare.id]
    )
    vector_store.save()


def batch_store_embeddings(db: Session, batch_size: int = 100):
    """
    ëª¨ë“  ë³µì§€ ì •ë³´ì˜ ì„ë² ë”©ì„ ì¼ê´„ ìƒì„±í•˜ì—¬ ì €ì¥
    - DBì—ì„œ ì„ë² ë”©ì´ ì—†ëŠ” ë³µì§€ ì •ë³´ë¥¼ ê°€ì ¸ì™€ì„œ ì²˜ë¦¬
    """
    # ì„ë² ë”©ì´ ì—†ëŠ” ë³µì§€ ì •ë³´ ì¡°íšŒ
    welfares = db.query(models.Welfare).filter(
        models.Welfare.embedding.is_(None),
        models.Welfare.full_text.isnot(None)
    ).limit(batch_size).all()
    
    if not welfares:
        return 0
    
    vectors = []
    welfare_ids = []
    
    for welfare in welfares:
        if welfare.full_text:
            embedding = get_embedding(welfare.full_text)
            welfare.embedding = embedding
            vectors.append(embedding)
            welfare_ids.append(welfare.id)
    
    # DB ì»¤ë°‹
    db.commit()
    
    # ë²¡í„° DBì— ì¼ê´„ ì¶”ê°€
    if vectors:
        vector_store = get_vector_store()
        vector_store.add_vectors(
            np.array(vectors).astype('float32'),
            welfare_ids
        )
        vector_store.save()
    
    return len(welfare_ids)


def load_welfares_to_vector_db(db: Session, force_rebuild: bool = False):
    """
    DBì— ìˆëŠ” ë³µì§€ ì •ë³´ë¥¼ ë²¡í„° DB(FAISS)ì— ë¡œë“œ
    - ì„œë²„ ì‹œì‘ ì‹œ í˜¸ì¶œ
    - ì´ë¯¸ ì¸ë±ìŠ¤ê°€ ìˆê³  force_rebuild=Falseì´ë©´ ê¸°ì¡´ ì¸ë±ìŠ¤ ì‚¬ìš©
    
    Args:
        db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
        force_rebuild: Trueì´ë©´ ê¸°ì¡´ ì¸ë±ìŠ¤ë¥¼ ì‚­ì œí•˜ê³  ì¬êµ¬ì¶•
    """
    vector_store = get_vector_store()
    
    # ê¸°ì¡´ ì¸ë±ìŠ¤ê°€ ìˆê³  ì¬êµ¬ì¶•ì´ í•„ìš” ì—†ìœ¼ë©´ ìŠ¤í‚µ
    if not force_rebuild and vector_store.get_size() > 0:
        logger.info(f"âœ“ ê¸°ì¡´ ë²¡í„° ì¸ë±ìŠ¤ ì‚¬ìš©: {vector_store.get_size()}ê°œ ë²¡í„°")
        return
    
    # ì¬êµ¬ì¶•ì´ í•„ìš”í•œ ê²½ìš° ê¸°ì¡´ ì¸ë±ìŠ¤ ì‚­ì œ
    if force_rebuild:
        logger.info("ê¸°ì¡´ ë²¡í„° ì¸ë±ìŠ¤ ì‚­ì œ ì¤‘...")
        global _vector_store
        vector_store_path = os.path.join(settings.VECTOR_DB_PATH, "faiss.index")
        id_mapping_path = os.path.join(settings.VECTOR_DB_PATH, "id_mapping.pkl")
        if os.path.exists(vector_store_path):
            os.remove(vector_store_path)
        if os.path.exists(id_mapping_path):
            os.remove(id_mapping_path)
        _vector_store = None
        vector_store = get_vector_store()
    
    # DBì—ì„œ ë³µì§€ ì •ë³´ ì¡°íšŒ
    welfares = db.query(models.Welfare).filter(
        models.Welfare.full_text.isnot(None)
    ).all()
    
    if not welfares:
        logger.warning("ë²¡í„° DBì— ë¡œë“œí•  ë³µì§€ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    logger.info(f"ğŸ”„ ë²¡í„° DB ì´ˆê¸°í™” ì¤‘... (ì´ {len(welfares)}ê°œ í•­ëª©)")
    
    vectors = []
    welfare_ids = []
    new_embeddings_count = 0
    
    for i, welfare in enumerate(welfares):
        if welfare.full_text:
            # ì´ë¯¸ ì„ë² ë”©ì´ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ìƒì„± (ë¹„ìš© ì ˆê°)
            if not welfare.embedding:
                try:
                    embedding = get_embedding(welfare.full_text)
                    welfare.embedding = embedding
                    new_embeddings_count += 1
                except Exception as e:
                    logger.error(f"ì„ë² ë”© ìƒì„± ì‹¤íŒ¨ (ID: {welfare.id}): {e}")
                    continue
            else:
                embedding = welfare.embedding
            
            vectors.append(embedding)
            welfare_ids.append(welfare.id)
            
            # ë°°ì¹˜ë¡œ ë²¡í„° DBì— ì¶”ê°€ (100ê°œì”©)
            if len(vectors) >= 100:
                vector_store.add_vectors(
                    np.array(vectors).astype('float32'),
                    welfare_ids
                )
                vectors = []
                welfare_ids = []
                logger.info(f"  ì§„í–‰ ì¤‘: {i + 1}/{len(welfares)} (ìƒˆ ì„ë² ë”©: {new_embeddings_count}ê°œ)")
    
    # ë‚¨ì€ ë²¡í„° ì¶”ê°€
    if vectors:
        vector_store.add_vectors(
            np.array(vectors).astype('float32'),
            welfare_ids
        )
    
    # ì¸ë±ìŠ¤ ì €ì¥
    vector_store.save()
    
    # DB ì»¤ë°‹ (ìƒˆë¡œ ìƒì„±í•œ ì„ë² ë”© ì €ì¥)
    if new_embeddings_count > 0:
        try:
            db.commit()
            logger.info(f"âœ“ {new_embeddings_count}ê°œì˜ ìƒˆ ì„ë² ë”©ì„ DBì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            logger.error(f"DB ì»¤ë°‹ ì‹¤íŒ¨: {e}")
            db.rollback()
    
    logger.info(f"âœ… ë²¡í„° DB ì´ˆê¸°í™” ì™„ë£Œ: {vector_store.get_size()}ê°œ ë²¡í„° ì €ì¥ë¨")


def rebuild_vector_index(db: Session):
    """
    ë²¡í„° ì¸ë±ìŠ¤ë¥¼ ì¬êµ¬ì¶•í•©ë‹ˆë‹¤.
    - ëª¨ë“  ë³µì§€ ì •ë³´ì˜ ì„ë² ë”©ì„ ë‹¤ì‹œ ìƒì„±í•˜ì—¬ ë²¡í„° DBì— ì €ì¥
    """
    load_welfares_to_vector_db(db, force_rebuild=True)
