"""
RAG ì—”ì§„
- ë²¡í„° ê²€ìƒ‰ (FAISS)
- ë¬¸ì„œ ê²€ìƒ‰ ë¡œì§
- Upstage Embeddings í†µí•©
"""

from typing import List, Optional
from sqlalchemy.orm import Session
import numpy as np
import os
from pathlib import Path
import json
import pickle
import logging

from app.core.config import settings
from app.models import models
from app.ai_core.llm_client import llm_client
from app.ai_core.prompts import WELFARE_SUMMARY_PROMPT

logger = logging.getLogger(__name__)

# FAISS ì„í¬íŠ¸
try:
    import faiss
    FAISS_AVAILABLE = True
except ImportError:
    FAISS_AVAILABLE = False
    print("ê²½ê³ : FAISSê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install faiss-cpuë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")


class VectorStore:
    """FAISS ê¸°ë°˜ ë²¡í„° ì €ì¥ì†Œ"""
    
    def __init__(self, dimension: Optional[int] = None, index_path: Optional[str] = None):
        """
        dimension: ì„ë² ë”© ì°¨ì› (Noneì´ë©´ ì„¤ì •ì—ì„œ ìë™ ê°ì§€)
        index_path: FAISS ì¸ë±ìŠ¤ íŒŒì¼ ê²½ë¡œ
        """
        # ì°¨ì› ìë™ ê°ì§€ (ì„¤ì •ì—ì„œ ê°€ì ¸ì˜¤ê¸°)
        if dimension is None:
            dimension = settings.EMBEDDING_DIMENSION
        self.dimension = dimension
        self.index_path = index_path or os.path.join(settings.VECTOR_DB_PATH, "faiss.index")
        self.id_to_welfare_id_path = os.path.join(settings.VECTOR_DB_PATH, "id_mapping.pkl")
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(os.path.dirname(self.index_path), exist_ok=True)
        
        # FAISS ì¸ë±ìŠ¤ ì´ˆê¸°í™”
        if FAISS_AVAILABLE:
            if os.path.exists(self.index_path):
                self.index = faiss.read_index(self.index_path)
                # ID ë§¤í•‘ ë¡œë“œ
                if os.path.exists(self.id_to_welfare_id_path):
                    with open(self.id_to_welfare_id_path, 'rb') as f:
                        self.id_to_welfare_id = pickle.load(f)
                else:
                    self.id_to_welfare_id = {}
            else:
                # L2 ê±°ë¦¬ ê¸°ë°˜ ì¸ë±ìŠ¤ ìƒì„±
                self.index = faiss.IndexFlatL2(dimension)
                self.id_to_welfare_id = {}
        else:
            self.index = None
            self.id_to_welfare_id = {}
    
    def add_vectors(self, vectors: np.ndarray, welfare_ids: List[int]):
        """ë²¡í„°ì™€ welfare IDë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤."""
        if not FAISS_AVAILABLE or self.index is None:
            return
        
        if len(vectors) == 0:
            return
        
        # numpy ë°°ì—´ë¡œ ë³€í™˜
        if not isinstance(vectors, np.ndarray):
            vectors = np.array(vectors).astype('float32')
        
        # ì°¨ì› í™•ì¸
        if vectors.shape[1] != self.dimension:
            raise ValueError(f"ë²¡í„° ì°¨ì›ì´ ë§ì§€ ì•ŠìŠµë‹ˆë‹¤. ì˜ˆìƒ: {self.dimension}, ì‹¤ì œ: {vectors.shape[1]}")
        
        # í˜„ì¬ ì¸ë±ìŠ¤ í¬ê¸°
        start_id = self.index.ntotal
        
        # ì¸ë±ìŠ¤ì— ì¶”ê°€
        self.index.add(vectors)
        
        # ID ë§¤í•‘ ì €ì¥
        for i, welfare_id in enumerate(welfare_ids):
            self.id_to_welfare_id[start_id + i] = welfare_id
    
    def search(self, query_vector: np.ndarray, k: int = 10) -> List[int]:
        """
        ìœ ì‚¬ë„ ê²€ìƒ‰
        - query_vector: ì¿¼ë¦¬ ë²¡í„° (1ì°¨ì› ë°°ì—´)
        - k: ë°˜í™˜í•  ê²°ê³¼ ìˆ˜
        - ë°˜í™˜: welfare ID ë¦¬ìŠ¤íŠ¸
        """
        if not FAISS_AVAILABLE or self.index is None or self.index.ntotal == 0:
            return []
        
        # numpy ë°°ì—´ë¡œ ë³€í™˜
        if not isinstance(query_vector, np.ndarray):
            query_vector = np.array([query_vector]).astype('float32')
        else:
            query_vector = query_vector.reshape(1, -1).astype('float32')
        
        # ê²€ìƒ‰
        distances, indices = self.index.search(query_vector, min(k, self.index.ntotal))
        
        # welfare IDë¡œ ë³€í™˜
        welfare_ids = []
        for idx in indices[0]:
            if idx in self.id_to_welfare_id:
                welfare_ids.append(self.id_to_welfare_id[idx])
        
        return welfare_ids
    
    def save(self):
        """ì¸ë±ìŠ¤ë¥¼ íŒŒì¼ì— ì €ì¥í•©ë‹ˆë‹¤."""
        if not FAISS_AVAILABLE or self.index is None:
            return
        
        faiss.write_index(self.index, self.index_path)
        
        # ID ë§¤í•‘ ì €ì¥
        with open(self.id_to_welfare_id_path, 'wb') as f:
            pickle.dump(self.id_to_welfare_id, f)
    
    def get_size(self) -> int:
        """ì €ì¥ëœ ë²¡í„° ìˆ˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        if self.index is None:
            return 0
        return self.index.ntotal


# ì „ì—­ ë²¡í„° ì €ì¥ì†Œ ì¸ìŠ¤í„´ìŠ¤
_vector_store: Optional[VectorStore] = None


def get_vector_store() -> VectorStore:
    """ë²¡í„° ì €ì¥ì†Œ ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    global _vector_store
    if _vector_store is None:
        _vector_store = VectorStore()
    return _vector_store


def get_embedding(text: str, is_query: bool = False, provider: Optional[str] = None) -> List[float]:
    """
    í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ì„ë² ë”©
    - Upstage ë˜ëŠ” Gemini Embeddings API ì‚¬ìš©
    - í…ìŠ¤íŠ¸ ì •ì œ í›„ ì„ë² ë”© ìƒì„±
    
    Args:
        text: ì„ë² ë”©í•  í…ìŠ¤íŠ¸
        is_query: Trueì´ë©´ ì¿¼ë¦¬ ëª¨ë¸ ì‚¬ìš© (ê²€ìƒ‰ìš©), Falseì´ë©´ ë¬¸ì„œ ëª¨ë¸ ì‚¬ìš© (ì €ì¥ìš©)
        provider: "upstage" ë˜ëŠ” "gemini" (Noneì´ë©´ ì„¤ì •ê°’ ì‚¬ìš©)
    """
    if not text or not text.strip():
        # ê¸°ë³¸ ì°¨ì›
        return [0.0] * settings.EMBEDDING_DIMENSION
    
    # llm_clientì˜ get_text_embedding ë©”ì„œë“œ ì‚¬ìš©
    try:
        return llm_client.get_text_embedding(text, is_query=is_query, provider=provider)
    except Exception as e:
        logger.error(f"ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
        raise ValueError(
            f"ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}. "
            ".env íŒŒì¼ì— UPSTAGE_API_KEYë¥¼ í™•ì¸í•˜ì„¸ìš”."
        )


def similarity_search(
    query_embedding: List[float],
    limit: int = 10
) -> List[int]:
    """
    ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰
    - query_embedding: ì¿¼ë¦¬ ë²¡í„°
    - limit: ë°˜í™˜í•  ê²°ê³¼ ìˆ˜
    - ë°˜í™˜: welfare ID ë¦¬ìŠ¤íŠ¸
    """
    vector_store = get_vector_store()
    return vector_store.search(np.array(query_embedding), k=limit)


def search_welfare_rag(
    db: Session,
    query: str,
    region: Optional[str] = None,
    age: Optional[int] = None,
    limit: int = 10
) -> List[models.Welfare]:
    """
    í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (Hybrid Search)
    - Semantic Search (ë²¡í„° ìœ ì‚¬ë„) + Keyword Search ê²°í•©
    - Metadata Filtering (ì§€ì—­/ë‚˜ì´ í•„í„°)
    - LLM ìš”ì•½ ìƒì„±
    """
    from app.models.crud import search_welfares
    
    # ë¹ˆ ì¿¼ë¦¬ ì²˜ë¦¬
    if not query or not query.strip():
        logger.warning("ë¹ˆ ì¿¼ë¦¬ë¡œ ê²€ìƒ‰ ì‹œë„")
        return []
    
    query = query.strip()
    
    try:
        # 1. ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰ (Semantic Search)
        try:
            query_embedding = get_embedding(query, is_query=True)
            vector_welfare_ids = similarity_search(query_embedding, limit=limit * 3)
            logger.debug(f"ë²¡í„° ê²€ìƒ‰ ê²°ê³¼: {len(vector_welfare_ids)}ê°œ")
        except Exception as e:
            logger.error(f"ë²¡í„° ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            vector_welfare_ids = []
        
        # 2. í‚¤ì›Œë“œ ê²€ìƒ‰ (Keyword Search)
        try:
            keyword_welfares = search_welfares(
                db=db,
                keyword=query,
                region=None,  # í•„í„°ë§ì€ ë‚˜ì¤‘ì—
                age=None,
                skip=0,
                limit=limit * 3
            )
            keyword_welfare_ids = [w.id for w in keyword_welfares]
            logger.debug(f"í‚¤ì›Œë“œ ê²€ìƒ‰ ê²°ê³¼: {len(keyword_welfare_ids)}ê°œ")
        except Exception as e:
            logger.error(f"í‚¤ì›Œë“œ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            keyword_welfare_ids = []
    
        
        # 3. í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ ê³„ì‚°ì„ ìœ„í•œ í†µí•© ID ë¦¬ìŠ¤íŠ¸
        all_welfare_ids = list(set(vector_welfare_ids + keyword_welfare_ids))
        
        if not all_welfare_ids:
            # ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
            logger.info(f"ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ: '{query}'")
            return []
        
        # 4. DBì—ì„œ ë³µì§€ ì •ë³´ ì¡°íšŒ
        try:
            welfares = db.query(models.Welfare).filter(
                models.Welfare.id.in_(all_welfare_ids)
            ).all()
            
            if not welfares:
                logger.warning(f"DBì—ì„œ ë³µì§€ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {len(all_welfare_ids)}ê°œ ID")
                return []
        except Exception as e:
            logger.error(f"DB ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []
        
        # 5. í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ ê³„ì‚° ë° ì •ë ¬
        welfare_dict = {w.id: w for w in welfares}
        scored_welfares = []
        
        for welfare_id in all_welfare_ids:
            if welfare_id not in welfare_dict:
                continue
            
            welfare = welfare_dict[welfare_id]
            
            # ë²¡í„° ê²€ìƒ‰ ì ìˆ˜ (ìˆœìœ„ ê¸°ë°˜, ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)
            vector_score = 0.0
            if welfare_id in vector_welfare_ids:
                vector_rank = vector_welfare_ids.index(welfare_id)
                vector_score = 1.0 / (vector_rank + 1)  # ìˆœìœ„ê°€ ë†’ì„ìˆ˜ë¡ ì ìˆ˜ ë†’ìŒ
            
            # í‚¤ì›Œë“œ ê²€ìƒ‰ ì ìˆ˜ (ìˆœìœ„ ê¸°ë°˜)
            keyword_score = 0.0
            if welfare_id in keyword_welfare_ids:
                keyword_rank = keyword_welfare_ids.index(welfare_id)
                keyword_score = 1.0 / (keyword_rank + 1)
            
            # í‚¤ì›Œë“œ ë§¤ì¹­ ë³´ë„ˆìŠ¤ (ì œëª©/ìš”ì•½ì— ì§ì ‘ í¬í•¨ëœ ê²½ìš°)
            keyword_bonus = 0.0
            query_lower = query.lower()
            if welfare.title and query_lower in welfare.title.lower():
                keyword_bonus += 0.5
            if welfare.summary and query_lower in welfare.summary.lower():
                keyword_bonus += 0.3
            
            # í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ (ë²¡í„° 60% + í‚¤ì›Œë“œ 40% + ë³´ë„ˆìŠ¤)
            hybrid_score = (vector_score * 0.6) + (keyword_score * 0.4) + keyword_bonus
            
            scored_welfares.append((hybrid_score, welfare))
        
        # ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬
        scored_welfares.sort(key=lambda x: x[0], reverse=True)
        welfares = [w for _, w in scored_welfares]
        
        # 6. ì§€ì—­/ë‚˜ì´ í•„í„°ë§ (Metadata Filtering)
        if region:
            before_filter = len(welfares)
            welfares = [w for w in welfares if region in (w.region or "")]
            logger.debug(f"ì§€ì—­ í•„í„°ë§: {before_filter}ê°œ -> {len(welfares)}ê°œ")
        
        if age:
            before_filter = len(welfares)
            welfares = [
                w for w in welfares
                if (w.age_min is None or w.age_min <= age) and
                   (w.age_max is None or w.age_max >= age)
            ]
            logger.debug(f"ë‚˜ì´ í•„í„°ë§: {before_filter}ê°œ -> {len(welfares)}ê°œ")
        
        # 7. ìƒìœ„ limitê°œë§Œ ë°˜í™˜
        welfares = welfares[:limit]
        
        # 8. LLMì„ ì‚¬ìš©í•˜ì—¬ 17ì„¸ ìˆ˜ì¤€ìœ¼ë¡œ 3ì¤„ ìš”ì•½ ìƒì„±
        for welfare in welfares:
            if not welfare.summary and welfare.full_text:
                try:
                    welfare.summary = summarize_welfare(welfare.full_text)
                except Exception as e:
                    logger.error(f"ìš”ì•½ ìƒì„± ì˜¤ë¥˜ (ID: {welfare.id}): {e}")
                    # ìš”ì•½ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ìš”ì•½ ì‚¬ìš©
                    welfare.summary = welfare.full_text[:200] + "..." if len(welfare.full_text) > 200 else welfare.full_text
        
        logger.info(f"í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì™„ë£Œ: '{query}' -> {len(welfares)}ê°œ ê²°ê³¼")
        return welfares
    
    except Exception as e:
        logger.error(f"í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ í‚¤ì›Œë“œ ê²€ìƒ‰ìœ¼ë¡œ ëŒ€ì²´
        try:
            logger.info(f"í‚¤ì›Œë“œ ê²€ìƒ‰ìœ¼ë¡œ ëŒ€ì²´ ì‹œë„: '{query}'")
            return search_welfares(
                db=db,
                keyword=query,
                region=region,
                age=age,
                skip=0,
                limit=limit
            )
        except Exception as fallback_error:
            logger.error(f"í‚¤ì›Œë“œ ê²€ìƒ‰ ëŒ€ì²´ë„ ì‹¤íŒ¨: {fallback_error}")
            return []


def summarize_welfare(text: str, target_level: str = "17ì„¸") -> str:
    """
    ë³µì§€ ì •ë³´ë¥¼ 17ì„¸ ìˆ˜ì¤€ìœ¼ë¡œ ìš”ì•½
    - LLM API í†µí•©
    """
    prompt = WELFARE_SUMMARY_PROMPT.format(
        target_level=target_level,
        text=text
    )
    
    # LLM API í˜¸ì¶œ
    summary = llm_client.summarize_text(text, target_level)
    
    return summary


def store_welfare_embedding(db: Session, welfare: models.Welfare):
    """
    ë³µì§€ ì •ë³´ì˜ ì„ë² ë”©ì„ ìƒì„±í•˜ì—¬ ì €ì¥
    - DBì— ì„ë² ë”© ì €ì¥
    - ë²¡í„° DBì—ë„ ì €ì¥
    """
    if not welfare.full_text:
        return
    
    # ì„ë² ë”© ìƒì„±
    embedding = get_embedding(welfare.full_text)
    
    # DBì— ì €ì¥
    welfare.embedding = embedding
    db.commit()
    
    # ë²¡í„° DBì— ì¶”ê°€
    vector_store = get_vector_store()
    vector_store.add_vectors(
        np.array([embedding]).astype('float32'),
        [welfare.id]
    )
    vector_store.save()


def batch_store_embeddings(db: Session, batch_size: int = 100):
    """
    ëª¨ë“  ë³µì§€ ì •ë³´ì˜ ì„ë² ë”©ì„ ì¼ê´„ ìƒì„±í•˜ì—¬ ì €ì¥
    - DBì—ì„œ ì„ë² ë”©ì´ ì—†ëŠ” ë³µì§€ ì •ë³´ë¥¼ ê°€ì ¸ì™€ì„œ ì²˜ë¦¬
    """
    # ì„ë² ë”©ì´ ì—†ëŠ” ë³µì§€ ì •ë³´ ì¡°íšŒ
    welfares = db.query(models.Welfare).filter(
        models.Welfare.embedding.is_(None),
        models.Welfare.full_text.isnot(None)
    ).limit(batch_size).all()
    
    if not welfares:
        return 0
    
    vectors = []
    welfare_ids = []
    
    for welfare in welfares:
        if welfare.full_text:
            embedding = get_embedding(welfare.full_text)
            welfare.embedding = embedding
            vectors.append(embedding)
            welfare_ids.append(welfare.id)
    
    # DB ì»¤ë°‹
    db.commit()
    
    # ë²¡í„° DBì— ì¼ê´„ ì¶”ê°€
    if vectors:
        vector_store = get_vector_store()
        vector_store.add_vectors(
            np.array(vectors).astype('float32'),
            welfare_ids
        )
        vector_store.save()
    
    return len(welfare_ids)


def load_welfares_to_vector_db(db: Session, force_rebuild: bool = False):
    """
    DBì— ìˆëŠ” ë³µì§€ ì •ë³´ë¥¼ ë²¡í„° DB(FAISS)ì— ë¡œë“œ
    - ì„œë²„ ì‹œì‘ ì‹œ í˜¸ì¶œ
    - ì´ë¯¸ ì¸ë±ìŠ¤ê°€ ìˆê³  force_rebuild=Falseì´ë©´ ê¸°ì¡´ ì¸ë±ìŠ¤ ì‚¬ìš©
    
    Args:
        db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
        force_rebuild: Trueì´ë©´ ê¸°ì¡´ ì¸ë±ìŠ¤ë¥¼ ì‚­ì œí•˜ê³  ì¬êµ¬ì¶•
    """
    vector_store = get_vector_store()
    
    # ê¸°ì¡´ ì¸ë±ìŠ¤ê°€ ìˆê³  ì¬êµ¬ì¶•ì´ í•„ìš” ì—†ìœ¼ë©´ ìŠ¤í‚µ
    if not force_rebuild and vector_store.get_size() > 0:
        logger.info(f"âœ“ ê¸°ì¡´ ë²¡í„° ì¸ë±ìŠ¤ ì‚¬ìš©: {vector_store.get_size()}ê°œ ë²¡í„°")
        return
    
    # ì¬êµ¬ì¶•ì´ í•„ìš”í•œ ê²½ìš° ê¸°ì¡´ ì¸ë±ìŠ¤ ì‚­ì œ
    if force_rebuild:
        logger.info("ê¸°ì¡´ ë²¡í„° ì¸ë±ìŠ¤ ì‚­ì œ ì¤‘...")
        global _vector_store
        vector_store_path = os.path.join(settings.VECTOR_DB_PATH, "faiss.index")
        id_mapping_path = os.path.join(settings.VECTOR_DB_PATH, "id_mapping.pkl")
        if os.path.exists(vector_store_path):
            os.remove(vector_store_path)
        if os.path.exists(id_mapping_path):
            os.remove(id_mapping_path)
        _vector_store = None
        vector_store = get_vector_store()
    
    # DBì—ì„œ ë³µì§€ ì •ë³´ ì¡°íšŒ
    welfares = db.query(models.Welfare).filter(
        models.Welfare.full_text.isnot(None)
    ).all()
    
    if not welfares:
        logger.warning("ë²¡í„° DBì— ë¡œë“œí•  ë³µì§€ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    logger.info(f"ğŸ”„ ë²¡í„° DB ì´ˆê¸°í™” ì¤‘... (ì´ {len(welfares)}ê°œ í•­ëª©)")
    
    vectors = []
    welfare_ids = []
    new_embeddings_count = 0
    
    for i, welfare in enumerate(welfares):
        if welfare.full_text:
            # ì´ë¯¸ ì„ë² ë”©ì´ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ìƒì„± (ë¹„ìš© ì ˆê°)
            if not welfare.embedding:
                try:
                    embedding = get_embedding(welfare.full_text)
                    welfare.embedding = embedding
                    new_embeddings_count += 1
                except Exception as e:
                    logger.error(f"ì„ë² ë”© ìƒì„± ì‹¤íŒ¨ (ID: {welfare.id}): {e}")
                    continue
            else:
                embedding = welfare.embedding
            
            vectors.append(embedding)
            welfare_ids.append(welfare.id)
            
            # ë°°ì¹˜ë¡œ ë²¡í„° DBì— ì¶”ê°€ (100ê°œì”©)
            if len(vectors) >= 100:
                vector_store.add_vectors(
                    np.array(vectors).astype('float32'),
                    welfare_ids
                )
                vectors = []
                welfare_ids = []
                logger.info(f"  ì§„í–‰ ì¤‘: {i + 1}/{len(welfares)} (ìƒˆ ì„ë² ë”©: {new_embeddings_count}ê°œ)")
    
    # ë‚¨ì€ ë²¡í„° ì¶”ê°€
    if vectors:
        vector_store.add_vectors(
            np.array(vectors).astype('float32'),
            welfare_ids
        )
    
    # ì¸ë±ìŠ¤ ì €ì¥
    vector_store.save()
    
    # DB ì»¤ë°‹ (ìƒˆë¡œ ìƒì„±í•œ ì„ë² ë”© ì €ì¥)
    if new_embeddings_count > 0:
        try:
            db.commit()
            logger.info(f"âœ“ {new_embeddings_count}ê°œì˜ ìƒˆ ì„ë² ë”©ì„ DBì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            logger.error(f"DB ì»¤ë°‹ ì‹¤íŒ¨: {e}")
            db.rollback()
    
    logger.info(f"âœ… ë²¡í„° DB ì´ˆê¸°í™” ì™„ë£Œ: {vector_store.get_size()}ê°œ ë²¡í„° ì €ì¥ë¨")


def rebuild_vector_index(db: Session):
    """
    ë²¡í„° ì¸ë±ìŠ¤ë¥¼ ì¬êµ¬ì¶•í•©ë‹ˆë‹¤.
    - ëª¨ë“  ë³µì§€ ì •ë³´ì˜ ì„ë² ë”©ì„ ë‹¤ì‹œ ìƒì„±í•˜ì—¬ ë²¡í„° DBì— ì €ì¥
    """
    load_welfares_to_vector_db(db, force_rebuild=True)
